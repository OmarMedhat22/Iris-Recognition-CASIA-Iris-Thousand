{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import glob\n",
    "import keras\n",
    "from keras.models       import Model\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Model\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=[]\n",
    "final_output_84_84=[]\n",
    "lables=[]\n",
    "for filefilepath in glob.iglob('final_casia/*'):\n",
    "    \n",
    "    \n",
    "    if filefilepath[-1] == 'g':\n",
    "        \n",
    "        img\t= cv2.imread(filefilepath)\n",
    "        imgs_colored=cv2.imread(filefilepath)\n",
    "        #img=cv2.resize(img,(200,150))\n",
    "        #imgs_colored.append(img)\n",
    "\n",
    "        print(filefilepath)\n",
    "        #print(filefilepath[19:-6])\n",
    "        #print(filefilepath[-5])\n",
    "        split = filefilepath.split(\".\")\n",
    "        #print(split)\n",
    "        print(split[0][12:])\n",
    "        print(split[1])\n",
    "\n",
    "        label=split[0][12:]\n",
    "        example_number = split[1]\n",
    "        imgs.append([imgs_colored,int(label)])\n",
    "        #final_output_84_84.append(imgs_colored)\n",
    "        #lables.append(int(label))\n",
    "    \n",
    "import random\n",
    "\n",
    "random.shuffle(imgs)\n",
    "\n",
    "for i,j in imgs:\n",
    "        final_output_84_84.append(i)\n",
    "        lables.append(j)\n",
    "    \n",
    "print(len(final_output_84_84))\n",
    "print(len(lables))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=(70,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=keras.utils.to_categorical(lables, num_classes=1000, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_84_84 = np.array(final_output_84_84,dtype=\"float16\")/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models       import Model\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "#original_model = VGG16(include_top=False)\n",
    "original_model = DenseNet201(include_top=False)\n",
    "#original_model = InceptionV3(include_top=False)\n",
    "#original_model = InceptionResNetV2(include_top=False)\n",
    "#original_model = Xception(include_top=False)\n",
    "\n",
    "bottleneck_input  = original_model.get_layer(index=0).input\n",
    "bottleneck_output = original_model.get_layer(index=-59).output\n",
    "bottleneck_model  = Model(inputs=bottleneck_input,  outputs=bottleneck_output)\n",
    "\n",
    "bottleneck_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#bottleneck_model = InceptionV3(include_top=False)\n",
    "#Inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottleneck_model    = VGG16(include_top=False)\n",
    "#bottleneck_model.summary()\n",
    "'''\n",
    "bottleneck_model   = DenseNet201(include_top=False)\n",
    "bottleneck_model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = final_output_84_84[0]\n",
    "test = test.reshape(1, img_size[0], img_size[1],3)\n",
    "test_shape = bottleneck_model.predict(test).shape\n",
    "print(test_shape)\n",
    "shape = (final_output_84_84.shape[0],test_shape[1],test_shape[2],test_shape[3])\n",
    "print(shape)\n",
    "print(shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottelneck_features = []\n",
    "for i in final_output_84_84:\n",
    "    \n",
    "    i = i.reshape(1, img_size[0], img_size[1],3)\n",
    "    bottelneck_features.append(bottleneck_model.predict(i))\n",
    "    print(len(bottelneck_features))\n",
    "    \n",
    "    #if len(bottelneck_features)==20000:\n",
    "        #break\n",
    "    \n",
    "bottelneck_features=np.array(bottelneck_features)\n",
    "print(bottelneck_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.amax(ubiris_features)  )\n",
    "bottelneck_features =  bottelneck_features.reshape(shape) #4, 6, 512\n",
    "print(bottelneck_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(final_output_84_84, lables,test_size=0.05, random_state=1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(final_output_84_84.shape[1:])))#4, 6, 512\n",
    "#model.add(Dense(500, activation='relu'))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "sgd = optimizers.SGD(lr=0.1)\n",
    "#adam = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='casia_dense_net_0.2_adam.hdf5', verbose=1, save_best_only=True)\n",
    "#X_train, X_test, y_train, y_test\n",
    "\n",
    "history=model.fit(X_train,y_train, batch_size=32, epochs=30, shuffle=True,validation_data=(X_test, y_test), verbose=1 ,callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras = keras_model.predict(X_test).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
